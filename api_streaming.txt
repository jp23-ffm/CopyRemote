# views.py - Stratégie en couches

def api_servers(request):
    server_ids = request.GET.getlist('id')
    count = len(server_ids)
    
    # Niveau 1: Petit volume (< 100) - Réponse normale
    if count <= 100:
        servers = Server.objects.filter(id__in=server_ids)
        serializer = ServerSerializer(servers, many=True)
        return Response(serializer.data)
    
    # Niveau 2: Volume moyen (100-500) - Streaming
    elif count <= 500:
        return stream_servers(server_ids)
    
    # Niveau 3: Gros volume (> 500) - Asynchrone obligatoire
    else:
        # Vérifier rate limit (max 5 gros exports par heure)
        if not check_rate_limit(request.user, 'big_export', 5, 3600):
            return Response({
                "error": "Trop d'exports récents. Attendez 1 heure."
            }, status=429)
        
        # Lance tâche async
        task = generate_server_export.delay(
            server_ids,
            request.user.email
        )
        
        return Response({
            "status": "queued",
            "task_id": task.id,
            "message": f"Export de {count} serveurs en cours",
            "check_status": f"/api/tasks/{task.id}/",
            "estimated_time": f"~{count // 200} minutes"
        }, status=202)

def stream_servers(server_ids):
    """Streaming pour volumes moyens"""
    def generate():
        yield b'{"servers":['
        first = True
        
        queryset = Server.objects.filter(id__in=server_ids).only(
            'id', 'name', 'ip', 'status'  # Seulement les champs nécessaires
        )
        
        for server in queryset.iterator(chunk_size=100):
            if not first:
                yield b','
            
            data = {
                'id': server.id,
                'name': server.name,
                'ip': server.ip,
                'status': server.status
            }
            yield json.dumps(data).encode('utf-8')
            first = False
        
        yield b']}'
    
    return StreamingHttpResponse(
        generate(),
        content_type='application/json'
    )
	
	
--------------------------


from django.http import StreamingHttpResponse
import zipfile
import io

def export_servers(request):
    server_ids = request.GET.getlist('id')
    
    def generate_zip():
        """Génère et streame le ZIP au fur et à mesure"""
        
        # Crée un ZIP en mémoire
        zip_buffer = io.BytesIO()
        
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # Génère CSV par chunks
            csv_data = io.StringIO()
            writer = csv.writer(csv_data)
            
            # Headers
            writer.writerow(['ID', 'Name', 'Status', ...])
            
            # Données par chunks de 1000
            for i in range(0, len(server_ids), 1000):
                chunk_ids = server_ids[i:i+1000]
                servers = Server.objects.filter(id__in=chunk_ids).iterator()
                
                for server in servers:
                    writer.writerow([server.id, server.name, ...])
                
                # Flush vers le ZIP tous les 1000
                if i % 1000 == 0:
                    csv_content = csv_data.getvalue().encode('utf-8')
                    zip_file.writestr(f'servers_part_{i}.csv', csv_content)
                    csv_data = io.StringIO()
                    writer = csv.writer(csv_data)
            
            # Derniers serveurs
            csv_content = csv_data.getvalue().encode('utf-8')
            zip_file.writestr('servers_final.csv', csv_content)
        
        # Retourne le ZIP
        zip_buffer.seek(0)
        yield zip_buffer.read()
    
    response = StreamingHttpResponse(
        generate_zip(),
        content_type='application/zip'
    )
    response['Content-Disposition'] = 'attachment; filename="servers.zip"'
    
    return response