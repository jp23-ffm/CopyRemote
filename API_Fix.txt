def _stream_json_response(self, queryset, serializer_class, count, fields,
                          excludefields, default_exclude):
    
    def generate():
        yield b'{"count": '
        yield str(count).encode('utf-8')
        yield b', "results": ['
        
        first = True
        offset = 0
        batch_size = self.STREAMING_CHUNK_SIZE  # 1000
        
        while True:
            # Charge un batch complet
            batch = list(queryset[offset:offset + batch_size])
            
            if not batch:
                break
            
            # SÉRIALISE LE BATCH ENTIER (many=True)
            serializer = serializer_class(
                batch,
                many=True,  # ← LA CLÉ !
                fields=fields,
                excludefields=excludefields,
                default_exclude=default_exclude
            )
            
            # Récupère toutes les données du batch
            batch_data = serializer.data
            
            # Stream les objets du batch
            for obj_data in batch_data:
                if not first:
                    yield b','
                first = False
                yield json.dumps(obj_data).encode('utf-8')
            
            offset += batch_size
        
        yield b']}'
    
    response = StreamingHttpResponse(
        generate(),
        content_type='application/json'
    )
    response['X-Total-Count'] = str(count)
    response['Cache-Control'] = 'no-cache'
    return response
	
	
	
def _stream_csv_response(self, queryset, serializer_class, fields, 
                         excludefields, default_exclude):
    
    def generate():
        pseudo_buffer = Echo()
        writer = csv.writer(pseudo_buffer)
        
        # Header
        header = serializer_class(
            queryset.first(), 
            fields=fields, 
            excludefields=excludefields, 
            default_exclude=default_exclude
        ).data.keys()
        yield writer.writerow(header)
        
        # Data par batch
        offset = 0
        batch_size = self.STREAMING_CHUNK_SIZE
        
        while True:
            batch = list(queryset[offset:offset + batch_size])
            if not batch:
                break
            
            # Sérialise le batch entier
            serializer = serializer_class(
                batch,
                many=True,
                fields=fields,
                excludefields=excludefields,
                default_exclude=default_exclude
            )
            
            # Stream les lignes du batch
            for data in serializer.data:
                yield writer.writerow(data.values())
            
            offset += batch_size
    
    response = StreamingHttpResponse(generate(), content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="data.csv"'
    return response
	
	
-------------------------


def _stream_json_response(self, queryset, serializer_class, count, fields,
                          excludefields, default_exclude):
    
    def generate():
        # Count UNE SEULE FOIS au début
        yield b'{"count": '
        yield str(count).encode('utf-8')
        yield b', "results": ['
        
        first = True
        offset = 0
        batch_size = self.STREAMING_CHUNK_SIZE
        
        while True:
            batch = list(queryset[offset:offset + batch_size])
            if not batch:
                break
            
            serializer = serializer_class(
                batch,
                many=True,
                fields=fields,
                excludefields=excludefields,
                default_exclude=default_exclude
            )
            
            for obj_data in serializer.data:
                if not first:
                    yield b','
                first = False
                yield json.dumps(obj_data).encode('utf-8')
            
            offset += batch_size
        
        # Ferme le JSON UNE SEULE FOIS à la fin
        yield b']}'
    
    # ...
	


def _stream_csv_response(self, queryset, serializer_class, fields, 
                         excludefields, default_exclude):
    
    def generate():
        pseudo_buffer = Echo()
        writer = csv.writer(pseudo_buffer)
        
        # Header UNE SEULE FOIS
        first_obj = queryset.first()
        if first_obj:
            header_serializer = serializer_class(
                first_obj, 
                fields=fields,
                excludefields=excludefields,
                default_exclude=default_exclude
            )
            yield writer.writerow(header_serializer.data.keys())
        
        # Data
        offset = 0
        batch_size = self.STREAMING_CHUNK_SIZE
        
        while True:
            batch = list(queryset[offset:offset + batch_size])
            if not batch:
                break
            
            serializer = serializer_class(
                batch,
                many=True,
                fields=fields,
                excludefields=excludefields,
                default_exclude=default_exclude
            )
            
            for data in serializer.data:
                yield writer.writerow(data.values())
            
            offset += batch_size
    
    # ...