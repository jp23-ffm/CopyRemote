# ========================================
# OPTIMISATIONS PRINCIPALES DE TA VUE
# ========================================

# Dans ta vue server_view, ligne ~690, tu as ce code pour le mode groupé :
"""
AVANT (code original - lignes ~740-800):
----------------------------------------
for server in current_page_servers:
    display_servers.append({
        'hostname': server.SERVER_ID,
        'count': 1,
        'total_count': 1,
        'hidden_count': 0,
        'has_hidden': False,
        'constant_fields': {},
        'variable_fields': {},
        'all_instances': [server],
        'primary_server': server,
        'annotation': annotations_dict.get(server.SERVER_ID)
    })
"""

# ✨ PROBLÈME ✨
# Tu créés un dictionnaire pour chaque serveur individuellement, 
# et tu dois ensuite les grouper. C'est inefficace !

# ========================================
# ✨ SOLUTION 1 : Utiliser select_related / prefetch_related ✨
# ========================================

# Dans ta vue, ligne ~470, tu fais :
# annotations = ServerAnnotation.objects.filter(SERVER_ID__in=hostnames_in_page)
# annotations_dict = {ann.SERVER_ID: ann for ann in annotations}

# ✅ C'EST DÉJÀ BON ! Mais tu peux améliorer avec :

# REMPLACE ligne ~470-473 par :
annotations_queryset = ServerAnnotation.objects.filter(
    SERVER_ID__in=hostnames_in_page
).only('SERVER_ID', 'notes', 'type', 'servicenow')  # ⭐ Sélectionne seulement les champs nécessaires

annotations_dict = {ann.SERVER_ID: ann for ann in annotations_queryset}


# ========================================
# ✨ SOLUTION 2 : Optimiser les requêtes de summary ✨
# ========================================

# Dans ta vue groupée (ligne ~560-600), tu as :
"""
if hostnames_in_page:
    summaries_queryset = ServerGroupSummary.objects.filter(SERVER_ID__in=hostnames_in_page)
    summaries_dict = {summary.SERVER_ID: summary for summary in summaries_queryset}
"""

# ✅ DÉJÀ BON ! Mais assure-toi d'avoir les indexes (voir models_optimized.py)

# Si tu veux optimiser encore plus, utilise .only() pour ne charger que les champs nécessaires :
summaries_queryset = ServerGroupSummary.objects.filter(
    SERVER_ID__in=hostnames_in_page
).only(
    'SERVER_ID', 
    'total_instances', 
    'constant_fields', 
    'variable_fields'
)  # ⭐ Ne charge pas last_updated si tu ne l'utilises pas


# ========================================
# ✨ SOLUTION 3 : Optimiser la pagination ✨
# ========================================

# Ligne ~680, tu convertis tout le queryset en liste avant de paginer :
# current_page_servers = list(page_obj_raw)

# ⚠️ PROBLÈME : Avec 400k serveurs, même filtré, c'est lourd !

# ✅ SOLUTION : Pagine AVANT de convertir en liste

# REMPLACE lignes ~265-280 par :
paginator = Paginator(filtered_servers, page_size)  # filtered_servers est un QuerySet
page_obj_raw = paginator.get_page(request.GET.get('page'))

# Maintenant page_obj_raw contient SEULEMENT les serveurs de la page actuelle
# Ensuite convertis en liste SEULEMENT cette page :
current_page_servers = list(page_obj_raw)  # ⭐ Beaucoup plus rapide !


# ========================================
# ✨ SOLUTION 4 : Utiliser values() pour les summaries ✨
# ========================================

# Si tu n'as besoin que de certains champs des summaries, utilise .values()
# au lieu de récupérer tous les objets :

summaries_data = ServerGroupSummary.objects.filter(
    SERVER_ID__in=hostnames_in_page
).values(
    'SERVER_ID',
    'total_instances',
    'constant_fields',
    'variable_fields'
)
summaries_dict = {s['SERVER_ID']: s for s in summaries_data}

# ⭐ Encore plus rapide car Django ne construit pas d'objets Python complets


# ========================================
# ✨ SOLUTION 5 : Batch les requêtes d'annotations ✨
# ========================================

# Au lieu de faire :
# for server_group in display_servers:
#     server_group['annotation'] = annotations_dict.get(server_group['hostname'])

# ✅ C'EST DÉJÀ OPTIMISÉ dans ton code ! Tu utilises un dictionnaire.


# ========================================
# ✨ SOLUTION 6 : Cache les field_labels.json ✨
# ========================================

# Ligne ~85-95, tu lis field_labels.json à CHAQUE requête !
# json_path=os.path.join(os.path.dirname(__file__), 'field_labels.json')
# with open(json_path, 'r', encoding="utf-8") as f:
#     json_data=json.load(f)

# ⚠️ PROBLÈME : Lecture disque à chaque fois = lent !

# ✅ SOLUTION : Cache en mémoire avec un import global

# Ajoute en HAUT de ton fichier views.py, après les imports :
import json
import os
from functools import lru_cache

@lru_cache(maxsize=1)
def get_field_labels():
    """
    Cache les field_labels en mémoire pour ne pas lire le fichier à chaque requête
    """
    json_path = os.path.join(os.path.dirname(__file__), 'field_labels.json')
    with open(json_path, 'r', encoding="utf-8") as f:
        return json.load(f)

# Puis dans ta vue, REMPLACE lignes ~85-95 par :
json_data = get_field_labels()

# ⭐ Le fichier sera lu UNE SEULE FOIS au démarrage, puis gardé en mémoire !


# ========================================
# ✨ SOLUTION 7 : Optimiser les filtres multiples ✨
# ========================================

# Ligne ~525-555, tu construis les filtres un par un
# C'est correct, mais tu peux simplifier avec Q objects :

from django.db.models import Q

# Au lieu de :
# for key, value in filters.items():
#     if isinstance(value, list):
#         terms = value
#     else:
#         terms = [value]
#     query = construct_query(key, terms)
#     all_servers = all_servers.filter(query)

# ✅ OPTIMISÉ : Combine tous les Q objects AVANT la requête
combined_query = Q()
for key, value in filters.items():
    if isinstance(value, list):
        terms = value
    else:
        terms = [value]
    
    query = construct_query(key, terms)
    combined_query &= query  # ⭐ Combine avec &= (AND)

# Une SEULE requête finale
all_servers = all_servers.filter(combined_query)

# ⭐ Django peut mieux optimiser la requête SQL quand tous les filtres sont combinés


# ========================================
# ✨ SOLUTION 8 : Index sur les champs de tri ✨
# ========================================

# Tu fais .order_by('SERVER_ID') partout (ligne ~682, ~685)
# ✅ SERVER_ID a déjà un index (db_index=True), donc c'est OK !

# Mais si tu ajoutes d'autres ORDER BY, assure-toi qu'ils ont des indexes.


# ========================================
# ✨ SOLUTION 9 : Éviter les conversions inutiles ✨
# ========================================

# Ligne ~690-700, en mode flat :
# current_page_servers = list(page_obj_raw)

# Si tu n'as besoin que de certains champs, utilise .values() :
if flat_view:
    # Au lieu de récupérer tous les objets Server complets
    current_page_servers = list(
        page_obj_raw.values(
            'SERVER_ID',
            'PAMELA_MODEL',
            'PAMELA_ENVIRONMENT',
            # ... liste tous les champs dont tu as besoin
        )
    )
    
    # ⭐ Plus rapide car Django ne crée pas d'objets Python complets


# ========================================
# RÉSUMÉ DES OPTIMISATIONS CRITIQUES
# ========================================
"""
1. ✅ Ajouter des indexes sur ServerGroupSummary (voir models_optimized.py)
2. ✅ Ajouter des indexes sur les champs de filtrage dans Server
3. ✅ Utiliser .only() ou .values() pour limiter les champs chargés
4. ✅ Combiner les Q objects pour une seule requête SQL
5. ✅ Cacher field_labels.json avec @lru_cache
6. ✅ Paginer AVANT de convertir en liste
7. ✅ Utiliser values() pour les données de summary

IMPACT ESTIMÉ :
- Requêtes sur ServerGroupSummary : 10-50x plus rapides
- Lecture de field_labels.json : éliminée après la 1ère requête
- Filtres multiples : 2-5x plus rapides
- Pagination : 2-3x plus rapides pour les grandes pages
"""

# ========================================
# COMMANDES À EXÉCUTER POUR APPLIQUER LES INDEXES
# ========================================
"""
1. Copie le fichier models_optimized.py dans ton app Django
2. Renomme-le en models.py (ou copie les modifications)
3. Exécute :

python manage.py makemigrations
python manage.py migrate

⚠️ ATTENTION : La création des indexes peut prendre plusieurs minutes
sur une table avec 400k entrées !

4. Pour vérifier que les indexes sont bien créés :

python manage.py dbshell

Puis dans PostgreSQL/MySQL :
\d userapp_server  -- Voir les indexes
\d userapp_servergroupsummary
"""
